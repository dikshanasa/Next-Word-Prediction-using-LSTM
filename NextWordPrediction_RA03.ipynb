{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NextWordPrediction_RA03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OgXqaS662DnC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM, Dropout\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import sys\n",
        "import heapq\n",
        "import seaborn as sns\n",
        "from pylab import rcParams"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 5\n",
        "\n",
        "path = '1661-0.txt'\n",
        "text = open(path).read().lower()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PmMPvyB2Gd-",
        "outputId": "dbdde25f-8450-42fc-9d4b-c0f0c583facc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length: 581888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQUENCE_LENGTH = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - SEQUENCE_LENGTH, step):\n",
        "    sentences.append(text[i: i + SEQUENCE_LENGTH])\n",
        "    next_chars.append(text[i + SEQUENCE_LENGTH])\n",
        "print(len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQzXLpcz2YGU",
        "outputId": "b4a09e22-a819-47b1-cbc8-cdda30d37afb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slge-gQQ2aEj",
        "outputId": "ff9f022d-e681-4ea4-9f97-88a445df412a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "ZmSlTKIh2e2n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"gere\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Rd6PfVa2f58",
        "outputId": "696af377-364f-4e95-824a-f025685161bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gere\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, y, validation_split=0.05, batch_size=128, epochs=20, shuffle=True).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf79OXHS2hp5",
        "outputId": "d44fa5a7-2fbd-4358-a308-c6bd279b73d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1440/1440 [==============================] - 202s 138ms/step - loss: 1.9814 - accuracy: 0.4190 - val_loss: 2.1107 - val_accuracy: 0.4105\n",
            "Epoch 2/20\n",
            "1440/1440 [==============================] - 190s 132ms/step - loss: 1.6265 - accuracy: 0.5128 - val_loss: 2.0326 - val_accuracy: 0.4437\n",
            "Epoch 3/20\n",
            "1440/1440 [==============================] - 188s 131ms/step - loss: 1.5213 - accuracy: 0.5423 - val_loss: 2.0281 - val_accuracy: 0.4483\n",
            "Epoch 4/20\n",
            "1440/1440 [==============================] - 191s 132ms/step - loss: 1.4675 - accuracy: 0.5554 - val_loss: 2.0255 - val_accuracy: 0.4595\n",
            "Epoch 5/20\n",
            "1440/1440 [==============================] - 193s 134ms/step - loss: 1.4319 - accuracy: 0.5656 - val_loss: 2.0250 - val_accuracy: 0.4604\n",
            "Epoch 6/20\n",
            "1440/1440 [==============================] - 193s 134ms/step - loss: 1.4081 - accuracy: 0.5717 - val_loss: 2.0191 - val_accuracy: 0.4603\n",
            "Epoch 7/20\n",
            "1440/1440 [==============================] - 192s 134ms/step - loss: 1.3875 - accuracy: 0.5779 - val_loss: 2.0110 - val_accuracy: 0.4640\n",
            "Epoch 8/20\n",
            "1440/1440 [==============================] - 191s 133ms/step - loss: 1.3720 - accuracy: 0.5803 - val_loss: 2.0322 - val_accuracy: 0.4616\n",
            "Epoch 9/20\n",
            "1440/1440 [==============================] - 192s 134ms/step - loss: 1.3582 - accuracy: 0.5847 - val_loss: 2.0358 - val_accuracy: 0.4600\n",
            "Epoch 10/20\n",
            "1440/1440 [==============================] - 193s 134ms/step - loss: 1.3465 - accuracy: 0.5871 - val_loss: 2.0341 - val_accuracy: 0.4585\n",
            "Epoch 11/20\n",
            "1440/1440 [==============================] - 193s 134ms/step - loss: 1.3373 - accuracy: 0.5904 - val_loss: 2.0461 - val_accuracy: 0.4639\n",
            "Epoch 12/20\n",
            "1440/1440 [==============================] - 193s 134ms/step - loss: 1.3280 - accuracy: 0.5927 - val_loss: 2.0405 - val_accuracy: 0.4658\n",
            "Epoch 13/20\n",
            "1440/1440 [==============================] - 192s 134ms/step - loss: 1.3203 - accuracy: 0.5942 - val_loss: 2.0490 - val_accuracy: 0.4689\n",
            "Epoch 14/20\n",
            "1440/1440 [==============================] - 192s 133ms/step - loss: 1.3131 - accuracy: 0.5957 - val_loss: 2.0444 - val_accuracy: 0.4704\n",
            "Epoch 15/20\n",
            "1440/1440 [==============================] - 193s 134ms/step - loss: 1.3071 - accuracy: 0.5977 - val_loss: 2.0716 - val_accuracy: 0.4687\n",
            "Epoch 16/20\n",
            "1440/1440 [==============================] - 194s 135ms/step - loss: 1.3015 - accuracy: 0.5986 - val_loss: 2.0475 - val_accuracy: 0.4754\n",
            "Epoch 17/20\n",
            "1440/1440 [==============================] - 195s 135ms/step - loss: 1.2964 - accuracy: 0.6013 - val_loss: 2.0940 - val_accuracy: 0.4621\n",
            "Epoch 18/20\n",
            "1440/1440 [==============================] - 193s 134ms/step - loss: 1.2920 - accuracy: 0.6021 - val_loss: 2.0789 - val_accuracy: 0.4666\n",
            "Epoch 19/20\n",
            "1440/1440 [==============================] - 194s 135ms/step - loss: 1.2889 - accuracy: 0.6023 - val_loss: 2.0347 - val_accuracy: 0.4699\n",
            "Epoch 20/20\n",
            "1440/1440 [==============================] - 193s 134ms/step - loss: 1.2844 - accuracy: 0.6031 - val_loss: 2.0892 - val_accuracy: 0.4639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('keras_model.h5')\n",
        "pickle.dump(history, open(\"history.p\", \"wb\"))"
      ],
      "metadata": {
        "id": "nty9snIk2j5Y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('keras_model.h5')\n",
        "history = pickle.load(open(\"history.p\", \"rb\"))"
      ],
      "metadata": {
        "id": "j-adNcd4CV9r"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_input(text):\n",
        "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
        "    for t, char in enumerate(text):\n",
        "        x[0, t, char_indices[char]] = 1.\n",
        "        \n",
        "    return x"
      ],
      "metadata": {
        "id": "Bi9DKOG3FV3C"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    \n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
      ],
      "metadata": {
        "id": "n-u5BQSCFXwx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_completion(text):\n",
        "    original_text = text\n",
        "    generated = text\n",
        "    completion = ''\n",
        "    while True:\n",
        "        x = prepare_input(text)\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds, top_n=1)[0]\n",
        "        next_char = indices_char[next_index]\n",
        "        text = text[1:] + next_char\n",
        "        completion += next_char\n",
        "        \n",
        "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
        "            return completion"
      ],
      "metadata": {
        "id": "Q9A8Np_2FZ3o"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_completions(text, n=3):\n",
        "    x = prepare_input(text)\n",
        " \n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "  \n",
        "    next_indices = sample(preds, n)\n",
        "    print(text)\n",
        "    \n",
        "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]\n",
        "\n"
      ],
      "metadata": {
        "id": "-y9DRBG9Fb0n"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quotes = [\n",
        "    \"It is not a lack of love, but a lack of friendship that makes unhappy marriages.\",\n",
        "    \"That which does not kill us makes us stronger.\",\n",
        "    \"I'm not upset that you lied to me, I'm upset that from now on I can't believe you.\",\n",
        "    \"And those who were seen dancing were thought to be insane by those who could not hear the music.\",\n",
        "    \"It is hard enough to remember my opinions, without also remembering my reasons for them!\"\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "wC2a-XwiFd2z"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for q in quotes:\n",
        "    seq = q[:40].lower()\n",
        "    print(seq)\n",
        "    print(predict_completions(seq, 5))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVGXvcrdFfwf",
        "outputId": "d0e9de42-f66b-4e57-cda2-631720e5cffc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it is not a lack of love, but a lack of \n",
            "it is not a lack of love, but a lack of \n",
            "['the ', 'strength ', 'a ', 'his ', 'bright ']\n",
            "\n",
            "that which does not kill us makes us str\n",
            "that which does not kill us makes us str\n",
            "['ength ', 'ick ', 'ange ', 'ong ', 'uck ']\n",
            "\n",
            "i'm not upset that you lied to me, i'm u\n",
            "i'm not upset that you lied to me, i'm u\n",
            "['nderstand ', 'se ', 'pon ', 'mplay ', 'gh ']\n",
            "\n",
            "and those who were seen dancing were tho\n",
            "and those who were seen dancing were tho\n",
            "['ught ', 'se ', 're ', 'nd ', 'med ']\n",
            "\n",
            "it is hard enough to remember my opinion\n",
            "it is hard enough to remember my opinion\n",
            "[' of ', '. ', 'al ', 's ', ', ']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complete_my_sentence= [\"who does a bit of simple cooking and keeps the place clean.\"]"
      ],
      "metadata": {
        "id": "RaRfkSIPGesO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for q in complete_my_sentence:\n",
        "    seq = q[:40].lower()\n",
        "    print(seq)\n",
        "    print(predict_completions(seq, 10))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztab29maGk1Y",
        "outputId": "99a45a36-8f15-449b-dee1-7b2a2624be60"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "who does a bit of simple cooking and kee\n",
            "who does a bit of simple cooking and kee\n",
            "['ped ', 'n ', 'med ', 'dver ', ' and ', 'bver, ', 'cked ', 'k ', 'gled ', '\\nthe ']\n",
            "\n"
          ]
        }
      ]
    }
  ]
}